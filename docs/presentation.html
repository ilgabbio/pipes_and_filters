<!DOCTYPE html>
<html>

<head>
  <title>Software Architectures for Computer Vision on Edge Devices</title>
  <meta charset="utf-8">
  <style>
    @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
    @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
    @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

    body {
      font-family: 'Droid Serif';
    }

    h1,
    h2,
    h3 {
      font-family: 'Yanone Kaffeesatz';
      font-weight: normal;
    }

    .remark-code,
    .remark-inline-code {
      font-family: 'Ubuntu Mono';
    }

    pre {
      margin: 0;
    }

    .remark-slide-content {
      font-size: 24px;
    }

    .cols {
      display: flex;
    }

    .col10 {
      flex: 10%;
    }

    .col20 {
      flex: 20%;
    }

    .col30 {
      flex: 30%;
    }

    .rowTitle,
    .rowTitle p {
      margin: 0;
    }

    .col40 {
      flex: 40%;
    }

    .col50 {
      flex: 50%;
    }

    .col60 {
      flex: 60%;
    }

    .col70 {
      flex: 70%;
    }

    .col80 {
      flex: 80%;
    }

    .col90 {
      flex: 90%;
    }

    .bib {
      font-size: 18px;
    }

    .compact,
    .compact ul {
      font-size: 22px;
      margin: 0;
      padding: 0;
    }

    .compact p {
      font-size: 22px;
      margin-top: 0;
      padding: 0;
    }

    .small,
    .small ul {
      font-size: 20px;
    }

    .tiny,
    .tiny ul {
      font-size: 18px;
    }

    .fancy {
      font-size: 120px;
      color: blue;
      margin: 0;
      padding: 0;
      text-shadow: 1px 1px 1px #000091,
        2px 2px 1px #000091,
        3px 3px 1px #000091,
        4px 4px 1px #000091,
        5px 5px 1px #000091,
        6px 6px 1px #000091,
        7px 7px 1px #000091,
        8px 8px 1px #000091,
        9px 9px 1px #000091,
        10px 10px 1px #000091,
        18px 18px 6px rgba(16, 16, 16, 0.4),
        22px 22px 10px rgba(16, 16, 16, 0.2),
        25px 25px 35px rgba(16, 16, 16, 0.2),
        30px 30px 60px rgba(16, 16, 16, 0.4);
    }
  </style>
</head>

<body>
  <textarea id="source">

class: center, middle

# Architectures for CV on the Edge

### Considerations from literature and real projects

---

# The faced problem

- Design **computer vision** applications:

  - running **real-time**:
      - constrained on **latency/throughput**;

  - on **edge devices**:
      - relying on **local resources**, no cloud access;

  - **CPU/GPU-intensive**:
      - composed by **native building blocks**.

---
exclude: true

# The faced problem

- Some examples we faced:

  - product quality monitoring:
      - multiple **interacting embedded devices**;

  - parking lot monitoring:
      - low **latency constraints** on some tasks;
      - low **computational power**;

  - road/driver real-time monitoring from mobile:
      - **real-time** needs for security;

  - photo-book generation from mobile;
      - **high troughput**, progressive processing;

---
exclude: true

# The faced problem

- Structure:

  - many **inter-dependent steps**;

  - **multiple** inputs/outputs;

  - outputs with different **priority**;

  - outputs with different **computational complexity**;

  - outputs with different **time constraints**;

  - configuration time **composeability**;

---

# A toy application

Detect face landmarks from camera and display them.

<pre class="mermaid">
  flowchart LR
  c([Camera]) --> p[Preprocess] --> f[Faces] --> l[Landmarks] --> d>Display]
</pre>
<br/>
.cols[
  .col50[.compact[
- **inter-dependent steps**;

- **multiple** inputs/outputs;

- different **priority**;

- different **complexity**;

- different **time constraints**;

- **composeability**.
  ]]
  .col50[
<center>
  <img src="images/example.png" width="410"/>
</center>
  ]
]

<center><small>
  Code on <a href="https://github.com/ilgabbio/pipes_and_filters">https://github.com/ilgabbio/pipes_and_filters</a>
</small></center>

---

# Base code

- We are using **native algorithms** implementations:
    - <small>OpenCV, Numpy, DLib, SimpleCV... many frameworks available.</small>

- Python is an **orchestrator** of CPU/GPU-intensive code;

- Parallelization can be adopted by algorithms.

<pre class="mermaid">
  classDiagram
    namespace Python {
      class Camera
      class Preprocess
      class Faces
      class Landmarks
      class Display
    }
    namespace Native {
      class CameraDriver
      class CvKernel
      class HaarCascade
      class LbfModel
      class GraphicLib
    }

    Camera .. CameraDriver
    Preprocess .. CvKernel
    Faces .. HaarCascade
    Landmarks .. LbfModel
    Display .. GraphicLib
</pre>

---

# Which architecture? &nbsp; Pipes and filters!

<pre class="mermaid">
  flowchart LR
    s(Source) -- pipe --> Filter1 -- pipe --> sk1(Sink1)
    s -- pipe --> Filter2 -- pipe --> sk2(Sink2)
    Filter1 -- pipe --> Filter2
</pre>

Let's try to answer some questions, such as:
.cols[
.col10[
&nbsp;
]
.col80[
.compact[.small[
- What are **pipes** and what guarantees must they offer?
- What are **filters** and what must offer?
- What about the **flow management** and optimization?
- How many **threads**/**machines** will the graph spread on?
- How can we **assemble** the system (who and how)?
- What about **configuration** of the system/hyperparametes?
- What about **communication** between components?
- How can we **interact** with the running system (in/out)?
- What **frameworks** are there and which to choose?
]]]
]

---

# P&F: Pipes allow filters to interact

.cols[
  .col70[
- **Directly**, function calls;

- **Across threads**:

  - Locking or not locking?
  - Lock-free solutions.
  - Is SP/SC the target?

- **Across machines**:

  - not on edge-devices;
  - unbound latency.

- **Transparently**, managed.
  ]
  .col30[
    <img src="images/queue.png" width="300"/>
  ]
]

---

# P&F: Topology.. what kind of graphs

--

.cols[
  .col20.rowTitle[
    Pipelines
  ]
  .col60[
    <pre class="mermaid">
      flowchart LR
      a --> b --> c --> d
    </pre>
  ]
  .col20.rowTitle[
    SP/SC
  ]
]

--

.cols[
  .col20.rowTitle[
    Trees
  ]
  .col60[
    <pre class="mermaid">
      flowchart LR
      a --> b --> c --> d
      b --> e --> f
    </pre>
  ]
  .col20.rowTitle[
    SP/MC<br/>Queue or pub/sub?
  ]
]

--

.cols[
  .col20.rowTitle[
    DAGs
  ]
  .col60[
    <pre class="mermaid">
      flowchart LR
      a --> b --> c --> e
      b --> d --> e --> f
    </pre>
  ]
  .col20.rowTitle[
    MP/MC<br/>Sync? How?
  ]
]

--

.cols[
  .col20.rowTitle[
    Arbitrary
  ]
  .col60[
    <pre class="mermaid">
      flowchart LR
      a --> b --> c --> e
      e --> d --> b
    </pre>
  ]
  .col20.rowTitle[
    Feedback loops
  ]
]

--

.rowTitle[
  NOTE: Constructs formalized in *stream algebra* [3].
]

---

# P&F: Filters

- **Callables** with arguments:
  - local processing, eventually on accelerated devices;
  - well-defined (typed) **ports**.

- **Lifecycle** management, **parameterization**:
  - can be manual, better if done with IoC/CDI.

.cols[
  .col70[
- User defined **code** that:
  - consumes some data;
  - can change its internal state;
  - produces some results.

- Can be **statefull** (better, if stateless).
  ]
  .col30[
<br/><br/><img src="images/filter.png" width="200"/>
  ]
]


---

# P&F flow management

**<big>What drives message flowing through P&Fs?</big>**

<center>
  <img src="images/flowing.jpg" width="500"/><br/><br/>
  What is <i>the pump</i>?
</center>

---

# P&F flow management: push

Example: a (simple) pipeline pattern implementation

.cols[
  .col50[
   ```python
class Step(ABC):
    def __or__(self, next: Step) -> Step:
      # Store the next step.
    
    def push(self, frame: dict | None):
      # Execute _op and push on next.

    @abstractmethod
    def _op(self, frame: dict):
        pass

    def close(self):
        pass
   ```
  ]
  .hspace[ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]
  .col50[
    <pre class="mermaid">
      classDiagram
        class Runner
        class Step {
          push(message | poison-pill)
          operation(message)
          close()
        }
        Step "next" o--> "0..1" Step
        Runner "runs" --> Step
    </pre>
  ]
]

.vspace[]

  ```python
# Composition and run: the runner pushes the whiteboard into the pipeline.
Runner(
    Source() | Preprocess() | Faces() | Landmarks() | Display()
).run()
  ```

---

# P&F flow management: pull

In Python can be achieved using generators:

.cols[
  .col50[
   ```python
def step(step_source):
  for frame in step_source:
    process(frame)
    update(frame)
    yield frame
   ```

  .vspace[]

   ```python
def source():
    # Initialization.

    while must not stop:
        yield new whiteboard

    # Finalization.
   ```

  .vspace[]

   ```python
# Runned by pulling:
for _ in pipeline:
    pass
   ```
  ]
  .hspace[ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]
  .col50[
    <pre class="mermaid">
      graph TD
      subgraph step
        subgraph previous
          subgraph ...
            source
          end
        end
      end

      runner --> |pulls| step
    </pre>
  ]
]

---

# P&F flow management: pull-push

More often we have a pull-push mix:

<center>
  <pre class="mermaid">
    sequenceDiagram
    participant P as Producer
    participant R as Runner
    participant C as Consumer
    R ->> +P: Pull
    activate R
    P -->> -R: message
    R ->> +C: Push(message)
    C -->> -R: Consumed
    deactivate R
  </pre>
  Happens in concurrent components using queues (the pump).
</center>

---

# P&F flow management: event-driven

- Filters are decoupled, **interacting with events**.

- Can be implemented using patterns, e.g.: **observer**.

- More decoupling using an **event-bus**:

<center>
  <pre class="mermaid">
    sequenceDiagram
    Filter1 -> Filter2: Indirect communication
    Note over Filter1, Filter2: Event-bus
  </pre>
</center>

.tiny[
<center>
Circuits and pyee are popular event management frameworks.
</center>
]

---

# P&F flow management: external

- Flow and concurrency are managed externally;

- Communication is mediated by mailboxes (pipes);

- Message processors are the concurrent actors (filters).

E.g.: actor systems provide this kind of flow management:

<pre class="mermaid">
  flowchart LR
  system((Actor System))
  subgraph Actor
    p([processing])
    subgraph Mailbox
      m1(message\nmessage\n...)
    end
  end
  subgraph a[Another actor]
    subgraph box[Mailbox]
      m2(message)
    end
  end
  p --> |sends| m2
  system --> |triggers| p
</pre>

---

# P&F flow management: Actor Systems

.cols[
 .col50[
  The system must manage:

  - isolation

  - synchronization

  - scheduling

  - distribution
 ]
 .col50[
  The system must be:

  - composed (configuration)

  - started (threads/network)

  - feeded (something pushes)
 ]
]

.cols[
  .col50[
```python
class StepActor(ActorBase):
  def __init__(self, dest):
    "Needs a reference to the target actor"
    self._dest = dest

  def on_receive(self, frame: dict):
    "Receives messages and sends results"
    self._dest.tell(process(frame))
```
.tiny[
Thespian, **Pykka**, *Xoscar*, to name a few.
]
  ]
  .col50[
  <p style="margin: -40px; margin-left: 50px;">
   <img src="images/messagingPatterns.jpg" width="200"/>
  </p>
  ]
]

---

# P&F flow management: timely

External flow management with **data generation** tracking:

<pre class="mermaid">
  flowchart LR
    Source --> |gen 3| Filter1 --> Filter2 --> |gen 2| Filter3 --> |gen 1| Sink
    Filter3 --> |gen 1| Filter1
</pre>

- Proposed by Microsoft Research in 2013 (Naiad);

- supports scaling on multiple threads/nodes;

- allows incremental update of results;

- reimplemented in Rust and wrapped by *bytewax*.

---

# P&F: Threading/Distribution

If algorithms have insufficient parallelization...

&nbsp;&nbsp;&nbsp;&nbsp;...what would you make concurrent in the graph?

<center>
  <img src="images/concurrency.png" width="550"/><br/>
  <small>
    <i> Efficient Engineering and Execution of Pipe-and-Filter Architectures </i>
  </small>
</center>

---

# P&F: Threading/Distribution

<pre class="mermaid">
  flowchart LR
    subgraph "thread 1"
      s(Source) -- pipe --> f1(Filter1)
      s -- pipe --> f2(Filter2)
    end
    subgraph "thread 2"
      f1 -- pipe --> f3(Filter3) -- pipe --> sk(Sink)
      f2 -- pipe --> f3
    end
</pre>

- Parallelization on one machine by means of **threads**:

  - at the **filter** level;
  - at the **sub-graph** level;
  - one thread per **graph**.

- Less is more, if possible **prevent distribution complexity**:

  - eventually splitting at the problem level.

---

# P&F threading: load balancing

How to **balance load** between threads?

<br/>

In **TeeTime** it is proposed to *adaptively transform* the graph: 

<center>
  <img src="images/balancing.png" width="600"/><br/>
  <small>
    <i>Efficient Engineering and Execution of Pipe-and-Filter Architectures</i>
  </small>
</center>

---

# P&F threading: load balancing

How to **balance load** between threads?

<br/>

**EPypes** proposes a framework to *split* the graph in a pipeline: 

<center>
  <pre class="mermaid">
    flowchart LR
      subgraph "thread 1"
        s(Source) --> f1(Filter1)
        s --> f2(Filter2) --> f3(Filter3)
        f1 --> f3
      end
      subgraph "thread 2"
        f3 -- pipe --> f4(Filter4) --> f5(Filter5) --> sk(Sink)
      end
  </pre>
  <small>
    <i>EPypes: a framework for building event-driven data processing pipelines</i>
  </small>
</center>

- Efficient within graph comm. with direct calls;

- efficient between graph comm. using SP/SC queues.

---

# P&F: Messages along the pipes

.cols[
  .col50[
Exactly **what needed**: <br>
  $\Rightarrow$ complex graphs; <br>
  $\Rightarrow$ no general channel.
  ]
  .col50[
```python
@define_block("LandmarksDetector",
              Input("gray"),
              Input("faces"),
              Output("landmarks"),
)
def landmarks(gray, faces):
  ... # Example with Barfi.
```
  ]
]

.vspace[]

.cols[
  .col50[
A **general container**: <br>
  $\Rightarrow$ complex message checking; <br>
  $\Rightarrow$ memory management.
  ]
  .col50[
```python
def landmarks_detector(source):
  for frame in source:
    # Input:
    faces = frame["shapes"]["faces"]
    gray = frame["gray"]
    # Output:
    frame["shapes"]["landmarks"] = ...
    yield frame
```
  ]
]

*Configuration* can be done **via IoC** (e.g. with Hydra)... <br>
&nbsp;&nbsp;&nbsp;...or can travel **with messages** (see EPypes).

*External notifications* require a **queue and a thread**... <br>
&nbsp;&nbsp;&nbsp;...**answers** & **commands** can travel with the whiteboard.

---

# P&F: Structure and assembly

- Graph described by the **code**:

  - **direct** composition of objects/functions;
  - design **patterns** (observer, pipeline, pub/sub).

- Graph described by the **configuration**:

  - graph representation **data structure**;
  - **Inversion of Control** (IoC) system description: <br>
    &nbsp;&nbsp;&nbsp;see *Hydra*, Dependency Injector.
  - event-based systems connected by **bus configuration**;
  - **auto-wiring** guided by in/out argument relations: <br>
    &nbsp;&nbsp;&nbsp;see `epypes_fw.py` and `autowiring.py`.

<pre class="mermaid">
  flowchart LR
    conf[[Configuration]] --> Graph1
    subgraph Graph1
      direction LR
      a --> b --> c
    end
    Graph1 --- pipe --> Graph2
    subgraph Graph2
      direction LR
      d --> e --> f
    end
</pre>

---

# P&F: Structure and assembly

A processing graph can be a complex structure:

<center>
  <img src="images/tee-time.png" width="700"/><br/><br/>
  See the <b>TeeTime framework</b>, Christian Wulf.
</center>

---

# Thanks for listening

.cols[
 .col30[
## Q&A
#### Bib
 ]
 .col70[
 <p class="fancy">(ツ)_/</p>
 ]
]

.bib[
1. *"Efficient Engineering and Execution of Pipe-and-Filter Architectures"*, M.Sc. Christian Wulf, 2019
1. *"EPypes: a framework for building event-driven data processing pipelines"*, Oleksandr Semeniuta, Petter Falkman, 2019
1. *"A Stream Algebra for Computer Vision Pipelines"*, Mohamed A. Helala, Ken Q. Pu, Faisal Z. Qureshi, 2014
1. *"Naiad: A Timely Dataflow System"*, Derek G. Murray, Frank McSherry, Rebecca Isaacs, Michael Isard, Paul Barham, Martìn Abadi, 2013
1. *"Software Architecture for Computer Vision: Beyond Pipes and Filters"*, Alexandre R.J. François, 2003
]

    </textarea>

  <script src="js/remark-latest.min.js"></script>
  <script src="js/mermaid.min.js"></script>
  <script src="js/katex.min.js"></script>
  <script src="js/auto-render.min.js"></script>

  <link rel="stylesheet" href="css/katex.min.css">

  <script>
    var slideshow = remark.create({}, () => {
      renderMathInElement(document.body, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
        ]
      });
    });
    // don't let mermaid automatically load on start
    mermaid.initialize({
      startOnLoad: false,
      cloneCssStyles: false
    });

    function initMermaidInSlide(slide) {
      var slideIndex = slide.getSlideIndex();
      // caution: no API to get the DOM element of current slide in remark, this might break in the future
      var currentSlideElement = document.querySelectorAll(".remark-slides-area .remark-slide")[slideIndex];
      var currentSlideMermaids = currentSlideElement.querySelectorAll(".mermaid");
      if (currentSlideMermaids.length !== 0) {
        mermaid.init(undefined, currentSlideMermaids);
      }
    }

    // first starting slide won't trigger the slide event, manually init mermaid
    initMermaidInSlide(slideshow.getSlides()[slideshow.getCurrentSlideIndex()])
    // on each slide event, trigger init mermaid
    slideshow.on('afterShowSlide', (slide) => {
      initMermaidInSlide(slide);
    });
  </script>
</body>

</html>